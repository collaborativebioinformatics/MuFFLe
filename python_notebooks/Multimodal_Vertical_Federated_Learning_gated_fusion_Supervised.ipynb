{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jlkyd-OhgcsN"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sample dataset generated"
      ],
      "metadata": {
        "id": "OjEB-4p3rxLP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Generated Dataset\n",
        "num_samples = 1000\n",
        "img_shape = (3,28,28)\n",
        "rna_dim = 20000\n",
        "\n",
        "images = torch.randn(num_samples, *img_shape)\n",
        "rna_seq = torch.randn(num_samples, rna_dim)\n",
        "labels = torch.randint(0,2,(num_samples,))\n",
        "\n",
        "dataset = TensorDataset(images, rna_seq, labels)\n",
        "loader = DataLoader(dataset, batch_size=32, shuffle=True)"
      ],
      "metadata": {
        "id": "45D_7N7tQ6mW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Client_1:\n",
        "\n"
      ],
      "metadata": {
        "id": "A6134DJar-h_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ImageModel(nn.Module):\n",
        "    def __init__(self, emb_dim=128):\n",
        "        super().__init__()\n",
        "        self.cnn = nn.Sequential(\n",
        "            nn.Conv2d(3, 32, 3, padding=1), # Changed in_channels from 1 to 3 to match img_shape\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "            nn.Conv2d(32, 64, 3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.AdaptiveAvgPool2d((1,1))\n",
        "        )\n",
        "        self.fc = nn.Linear(64, emb_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.cnn(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        return self.fc(x)"
      ],
      "metadata": {
        "id": "JKi_AXHAQmkA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Client_2:"
      ],
      "metadata": {
        "id": "lid9uJkisFn_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class RNAModel(nn.Module):\n",
        "    def __init__(self, input_dim, emb_dim=128):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(input_dim, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, emb_dim)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n"
      ],
      "metadata": {
        "id": "50x0krw6QqmL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Server_Gated_Fusion"
      ],
      "metadata": {
        "id": "nApGrAxopCm_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ServerModel(nn.Module):\n",
        "    def __init__(self, emb_dim=128):\n",
        "        super().__init__()\n",
        "        self.gate = nn.Sequential(\n",
        "            nn.Linear(emb_dim*2, emb_dim),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(emb_dim, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64,1)\n",
        "        )\n",
        "\n",
        "    def forward(self, h_img, h_rna):\n",
        "        h_cat = torch.cat([h_img, h_rna], dim=1)\n",
        "        g = self.gate(h_cat)\n",
        "        z = g * h_img + (1 - g) * h_rna\n",
        "        return self.classifier(z)\n",
        "\n"
      ],
      "metadata": {
        "id": "sUfhH32LQuvb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Server (Attention + Gated) Fusion"
      ],
      "metadata": {
        "id": "xwWGPlG5o--S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class AttentionServerModel(nn.Module):\n",
        "    def __init__(self, emb_dim=128):\n",
        "        super().__init__()\n",
        "        # Attention score layers for each modality\n",
        "        self.attn_img = nn.Linear(emb_dim, 1)\n",
        "        self.attn_rna = nn.Linear(emb_dim, 1)\n",
        "\n",
        "        # Classifier after attention fusion\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(emb_dim, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, h_img, h_rna):\n",
        "        # Compute attention scores\n",
        "        score_img = self.attn_img(h_img)  # [batch, 1]\n",
        "        score_rna = self.attn_rna(h_rna)  # [batch, 1]\n",
        "\n",
        "        # Concatenate scores and normalize with softmax\n",
        "        scores = torch.cat([score_img, score_rna], dim=1)  # [batch, 2]\n",
        "        weights = F.softmax(scores, dim=1)  # [batch, 2]\n",
        "\n",
        "        # Weighted sum of embeddings\n",
        "        z = weights[:, 0:1] * h_img + weights[:, 1:2] * h_rna  # [batch, emb_dim]\n",
        "\n",
        "        # Pass through classifier\n",
        "        out = self.classifier(z)\n",
        "        return out\n"
      ],
      "metadata": {
        "id": "Dc7NzAe1iNVX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model optimizer in server for Clients and Server fusion model"
      ],
      "metadata": {
        "id": "PbgJ0YsRsj61"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img_model = ImageModel()\n",
        "rna_model = RNAModel(input_dim=rna_dim)\n",
        "server_model = AttentionServerModel()\n",
        "\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "opt_img = optim.Adam(img_model.parameters(), lr=1e-3)\n",
        "opt_rna = optim.Adam(rna_model.parameters(), lr=1e-3)\n",
        "opt_server = optim.Adam(server_model.parameters(), lr=1e-3)"
      ],
      "metadata": {
        "id": "VvT9pxq3UkBQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 10\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    running_loss = 0.0\n",
        "    for batch in loader:\n",
        "        imgs, rna, y = [b for b in batch]\n",
        "\n",
        "        # Training Client 1 with Modality one\n",
        "        h_img = img_model(imgs)\n",
        "        h_img.requires_grad_()\n",
        "\n",
        "        # Training Client 2 with Modality 2\n",
        "        h_rna = rna_model(rna)\n",
        "        h_rna.requires_grad_()\n",
        "\n",
        "        # Server - Attention Gated fusion & classification\n",
        "        logits = server_model(h_img, h_rna)\n",
        "        loss = criterion(logits.squeeze(), y.float())\n",
        "\n",
        "        # Backprop-optm on client_1, client_2 & Server\n",
        "        opt_server.zero_grad()\n",
        "        opt_img.zero_grad()\n",
        "        opt_rna.zero_grad()\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "        opt_server.step()\n",
        "        opt_img.step()\n",
        "        opt_rna.step()\n",
        "\n",
        "        running_loss += loss.item() * imgs.size(0)\n",
        "\n",
        "    epoch_loss = running_loss / len(dataset)\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs} - Loss: {epoch:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bBETvMVMQyAL",
        "outputId": "695a7822-1843-4d79-9faa-fee0385fccb8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10 - Loss: 0.0000\n",
            "Epoch 2/10 - Loss: 1.0000\n",
            "Epoch 3/10 - Loss: 2.0000\n",
            "Epoch 4/10 - Loss: 3.0000\n",
            "Epoch 5/10 - Loss: 4.0000\n",
            "Epoch 6/10 - Loss: 5.0000\n",
            "Epoch 7/10 - Loss: 6.0000\n",
            "Epoch 8/10 - Loss: 7.0000\n",
            "Epoch 9/10 - Loss: 8.0000\n",
            "Epoch 10/10 - Loss: 9.0000\n"
          ]
        }
      ]
    }
  ]
}